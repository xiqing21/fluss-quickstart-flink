# Apache Flink æµå¤„ç†æ¶æ„å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) ğŸš€
2. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
3. [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
4. [ä¸šåŠ¡åœºæ™¯](#ä¸šåŠ¡åœºæ™¯)
5. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
6. [è¯¦ç»†æ‰§è¡Œæ­¥éª¤](#è¯¦ç»†æ‰§è¡Œæ­¥éª¤)
7. [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
8. [å®æ—¶ä¸šåŠ¡éªŒè¯](#å®æ—¶ä¸šåŠ¡éªŒè¯) â­
9. [é¢„æœŸæ•ˆæœéªŒè¯](#é¢„æœŸæ•ˆæœéªŒè¯)
10. [æŠ€æœ¯ç»†èŠ‚è§£é‡Š](#æŠ€æœ¯ç»†èŠ‚è§£é‡Š)
11. [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#æ€§èƒ½ä¼˜åŒ–å»ºè®®)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### âš¡ 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

å¦‚æœä½ æƒ³å¿«é€Ÿä½“éªŒæ•´ä¸ªApache Flinkæµå¤„ç†æ¶æ„ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š

```bash
# 1. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# 2. ç­‰å¾…æœåŠ¡å°±ç»ª (çº¦60ç§’)
sleep 60

# 3. æ‰§è¡Œæ‰€æœ‰SQLè„šæœ¬
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/1_cdc_source_to_kafka.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/2_dwd_layer.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/3_dimension_join.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/4_sink_to_postgres.sql

# 4. è¿è¡Œå®æ—¶éªŒè¯æµ‹è¯• â­
./realtime_validation_test.sh
```

### ğŸ¯ ä¸€é”®å¼éªŒè¯

**æœ€ç®€å•çš„æ–¹å¼ï¼šè¿è¡Œè‡ªåŠ¨åŒ–éªŒè¯è„šæœ¬**
```bash
# å‰æï¼šå·²å¯åŠ¨æœåŠ¡å¹¶æ‰§è¡Œå®Œæ‰€æœ‰SQLè„šæœ¬
./realtime_validation_test.sh
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
- âœ… è‡ªåŠ¨æ’å…¥æµ‹è¯•è®¢å•
- âœ… æ¨¡æ‹Ÿè®¢å•çŠ¶æ€å˜æ›´ï¼ˆPENDING â†’ SHIPPED â†’ COMPLETEDï¼‰
- âœ… éªŒè¯ç«¯åˆ°ç«¯æ•°æ®æµï¼ˆCDC â†’ DWD â†’ ç»´åº¦å…³è” â†’ PostgreSQLï¼‰
- âœ… æµ‹é‡å®æ—¶å¤„ç†å»¶è¿Ÿï¼ˆç›®æ ‡ï¼š<5ç§’ï¼‰
- âœ… ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š

**æˆåŠŸæ ‡å¿—**ï¼šçœ‹åˆ° `ğŸ‰ å®æ—¶éªŒè¯æµ‹è¯•é€šè¿‡ï¼` å’Œå»¶è¿ŸæŠ¥å‘Š

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„**å®æ—¶æ•°æ®å¤„ç†æ¶æ„**ï¼ŒåŸºäº Apache Flink å®ç°ä»æ•°æ®é‡‡é›†ã€æ¸…æ´—ã€è½¬æ¢åˆ°æœ€ç»ˆå­˜å‚¨çš„å…¨é“¾è·¯æµå¤„ç†ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- **å®æ—¶ CDC æ•°æ®æ•è·**ï¼šä» PostgreSQL å®æ—¶æ•è·æ•°æ®å˜æ›´
- **å¤šå±‚æ•°æ®æ¶æ„**ï¼šODS â†’ DWD â†’ DWS â†’ ADS åˆ†å±‚å¤„ç†
- **ç»´åº¦è¡¨å…³è”**ï¼šè®¢å•äº‹å®è¡¨ä¸ç”¨æˆ·ç»´åº¦è¡¨å®æ—¶å…³è”
- **æ•°æ®è´¨é‡ä¿è¯**ï¼šæ•°æ®æ¸…æ´—ã€æ ‡å‡†åŒ–ã€æ ¡éªŒ
- **å®æ—¶æ•°æ®å†™å…¥**ï¼šå¤„ç†ç»“æœå®æ—¶å†™å…¥ç›®æ ‡æ•°æ®åº“

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ¶æ„ç»„ä»¶
```
PostgreSQL (æº) â†’ CDC â†’ Kafka (ODS) â†’ Flink (DWD) â†’ Kafka (DWD) â†’ Flink (ç»´åº¦å…³è”) â†’ Kafka (ç»“æœ) â†’ PostgreSQL (ç›®æ ‡)
```

### æŠ€æœ¯æ ˆ
- **æµå¤„ç†å¼•æ“**ï¼šApache Flink 1.18
- **æ¶ˆæ¯é˜Ÿåˆ—**ï¼šApache Kafka 7.4.0
- **æ•°æ®åº“**ï¼šPostgreSQL 13
- **ç»´è¡¨å­˜å‚¨**ï¼šApache Fluss (å¯é€‰)
- **å®¹å™¨åŒ–**ï¼šDocker & Docker Compose
- **ç›‘æ§**ï¼šFlink Web UI (http://localhost:8081)

### èµ„æºé…ç½® (ä¼˜åŒ–ç‰ˆ)
- **JobManager**ï¼šé»˜è®¤å†…å­˜é…ç½®
- **TaskManager**ï¼š2ä¸ªå®ä¾‹ï¼Œæ¯ä¸ª4ä¸ªTask Slotsï¼Œé»˜è®¤å†…å­˜é…ç½®
- **æ€»è®¡**ï¼š8ä¸ªTask Slotsï¼Œè¶³å¤Ÿè¿è¡Œæ ‡å‡†çš„æµå¤„ç†ä½œä¸š
- **å¹¶è¡Œåº¦æ§åˆ¶**ï¼šè®¾ç½®ä¸º1ï¼Œé¿å…èµ„æºäº‰ç”¨

---

## ğŸ’¼ ä¸šåŠ¡åœºæ™¯

### ç”µå•†è®¢å•å®æ—¶å¤„ç†åœºæ™¯
æ¨¡æ‹Ÿç”µå•†å¹³å°çš„è®¢å•å¤„ç†æµç¨‹ï¼š
1. **è®¢å•æ•°æ®**ï¼šç”¨æˆ·ä¸‹å•æ—¶äº§ç”Ÿè®¢å•æ•°æ®
2. **ç”¨æˆ·ä¿¡æ¯**ï¼šå…³è”ç”¨æˆ·çš„è¯¦ç»†ä¿¡æ¯
3. **æ•°æ®æ¸…æ´—**ï¼šæ ‡å‡†åŒ–å•†å“åˆ†ç±»ã€çŠ¶æ€æè¿°
4. **å®æ—¶åˆ†æ**ï¼šåŸå¸‚åˆ†å±‚ã€ä»·æ ¼åˆ†æ
5. **ç»“æœè¾“å‡º**ï¼šç”Ÿæˆæœ€ç»ˆçš„è®¢å•åˆ†ææŠ¥è¡¨

### æ•°æ®æµè½¬
```
æºæ•°æ® â†’ å®æ—¶æ•è· â†’ æ•°æ®æ¸…æ´— â†’ ç»´åº¦å…³è” â†’ ç»“æœè¾“å‡º
```

---

## ğŸš€ ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**ï¼šmacOS/Linux/Windows
- **Docker**ï¼š20.10+
- **Docker Compose**ï¼š2.0+
- **å†…å­˜è¦æ±‚**ï¼šè‡³å°‘ 8GB å¯ç”¨å†…å­˜
- **ç£ç›˜ç©ºé—´**ï¼šè‡³å°‘ 5GB å¯ç”¨ç©ºé—´

### ä¾èµ–æ£€æŸ¥
```bash
# æ£€æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æ£€æŸ¥ Docker Compose ç‰ˆæœ¬
docker-compose --version

# æ£€æŸ¥å¯ç”¨å†…å­˜
free -h  # Linux
memory_pressure | head -5  # macOS
```

---

## ğŸ“ è¯¦ç»†æ‰§è¡Œæ­¥éª¤

### æ­¥éª¤ 1ï¼šé¡¹ç›®åˆå§‹åŒ–

```bash
# 1. å…‹éš†é¡¹ç›®æˆ–åˆ›å»ºå·¥ä½œç›®å½•
cd /path/to/your/workspace
mkdir flink-streaming-architecture
cd flink-streaming-architecture

# 2. ç¡®è®¤æ–‡ä»¶ç»“æ„
tree .
```

**é¢„æœŸç»“æœ**ï¼š
```
flink-streaming-architecture/
â”œâ”€â”€ docker-compose.yml                              # DockeræœåŠ¡é…ç½®
â”œâ”€â”€ start-streaming-architecture.sh                 # ç¯å¢ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ realtime_validation_test.sh                     # å®æ—¶éªŒè¯æµ‹è¯•è„šæœ¬
â”œâ”€â”€ README-Apache-Flink-æµå¤„ç†æ¶æ„å®Œæ•´æŒ‡å—.md        # å®Œæ•´ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ flink/
â”‚   â”œâ”€â”€ jars/                                       # Flinkè¿æ¥å™¨JARæ–‡ä»¶
â”‚   â””â”€â”€ sql/                                        # æ ‡å‡†åŒ–SQLè„šæœ¬
â”‚       â”œâ”€â”€ 1_cdc_source_to_kafka.sql               # CDCæ•°æ®é‡‡é›†
â”‚       â”œâ”€â”€ 2_dwd_layer.sql                         # DWDæ•°æ®æ¸…æ´—
â”‚       â”œâ”€â”€ 3_dimension_join.sql                    # ç»´åº¦è¡¨å…³è”
â”‚       â””â”€â”€ 4_sink_to_postgres.sql                  # æ•°æ®å†™å…¥
â”œâ”€â”€ postgres_source/
â”‚   â””â”€â”€ init/                                       # æºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
â””â”€â”€ postgres_sink/
    â””â”€â”€ init/                                       # ç›®æ ‡æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
```

### æ­¥éª¤ 2ï¼šå¯åŠ¨åŸºç¡€ç¯å¢ƒ

```bash
# å¯åŠ¨æµå¤„ç†æ¶æ„
docker-compose up -d

# ç­‰å¾…æ‰€æœ‰æœåŠ¡å¯åŠ¨ (çº¦2-3åˆ†é’Ÿ)
docker-compose ps
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… æ‰€æœ‰æœåŠ¡çŠ¶æ€ä¸º `healthy` æˆ– `running`
- âœ… PostgreSQL æºæ•°æ®åº“å¯è®¿é—® (localhost:5432)
- âœ… PostgreSQL ç›®æ ‡æ•°æ®åº“å¯è®¿é—® (localhost:5433)
- âœ… Kafka é›†ç¾¤è¿è¡Œæ­£å¸¸
- âœ… Flink é›†ç¾¤åŒ…å« 1ä¸ªJobManager + 2ä¸ªTaskManager
- âœ… Flink Web UI å¯è®¿é—® (http://localhost:8081)

### æ­¥éª¤ 3ï¼šéªŒè¯ç¯å¢ƒçŠ¶æ€

```bash
# 1. æ£€æŸ¥ Flink é›†ç¾¤çŠ¶æ€
curl -s http://localhost:8081/overview | python3 -m json.tool

# 2. æ£€æŸ¥ TaskManager èµ„æº
curl -s http://localhost:8081/taskmanagers | python3 -m json.tool

# 3. éªŒè¯æ•°æ®åº“è¿æ¥
docker exec -it postgres-source psql -U postgres -d source_db -c "SELECT COUNT(*) FROM business.orders;"
docker exec -it postgres-sink psql -U postgres -d sink_db -c "SELECT COUNT(*) FROM result.orders_with_user_info;"
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… Flink é›†ç¾¤æ˜¾ç¤º 8ä¸ªå¯ç”¨ Task Slots
- âœ… æºæ•°æ®åº“åŒ…å« 5æ¡è®¢å•æ•°æ®
- âœ… ç›®æ ‡æ•°æ®åº“è¡¨å·²åˆ›å»ºä½†æš‚æ— æ•°æ®

### æ­¥éª¤ 4ï¼šç¬¬ä¸€é˜¶æ®µ - CDC æ•°æ®æ•è·

```bash
# æ‰§è¡Œ CDC æ•°æ®æ•è· SQL
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/1_cdc_source_to_kafka.sql
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… åˆ›å»º CDC æºè¡¨ï¼š`business.orders` å’Œ `business.users`
- âœ… åˆ›å»º Kafka ç›®æ ‡è¡¨ï¼š`ods_orders_topic` å’Œ `ods_users_topic`
- âœ… æäº¤ 2ä¸ª Flink ä½œä¸š
- âœ… ä½œä¸šçŠ¶æ€ï¼šRUNNING

**éªŒè¯æ•°æ®æµ**ï¼š
```bash
# éªŒè¯ ODS å±‚æ•°æ®
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic ods_orders --from-beginning --max-messages 3
```

### æ­¥éª¤ 5ï¼šç¬¬äºŒé˜¶æ®µ - DWD æ•°æ®æ¸…æ´—

```bash
# æ‰§è¡Œ DWD æ•°æ®æ¸…æ´— SQL
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/2_dwd_layer.sql
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… åˆ›å»º DWD æºè¡¨ï¼šè¯»å– ODS å±‚æ•°æ®
- âœ… åˆ›å»º DWD ç›®æ ‡è¡¨ï¼šæ¸…æ´—åçš„æ•°æ®
- âœ… æäº¤ 1ä¸ª Flink ä½œä¸š
- âœ… æ•°æ®è½¬æ¢åŒ…æ‹¬ï¼š
  - å•†å“åˆ†ç±»æ ‡å‡†åŒ– (ç”µå­äº§å“â†’ELECTRONICS)
  - çŠ¶æ€æè¿°è½¬æ¢ (COMPLETEDâ†’å·²å®Œæˆ)
  - ä»·æ ¼æ ¼å¼åŒ– (æ·»åŠ Â¥ç¬¦å·)
  - æ—¶é—´å­—æ®µå¤„ç† (æ·»åŠ æ—¥æœŸã€å°æ—¶)

**éªŒè¯æ•°æ®å¤„ç†**ï¼š
```bash
# éªŒè¯ DWD å±‚æ•°æ®
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic dwd_orders --from-beginning --max-messages 3
```

### æ­¥éª¤ 6ï¼šç¬¬ä¸‰é˜¶æ®µ - ç»´åº¦å…³è”

```bash
# æ‰§è¡Œç»´åº¦å…³è” SQL
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/3_dimension_join.sql
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… åˆ›å»ºè®¢å•äº‹å®æµæºè¡¨
- âœ… åˆ›å»ºç”¨æˆ·ç»´åº¦è¡¨
- âœ… åˆ›å»ºæœ€ç»ˆç»“æœè¡¨
- âœ… æäº¤ 1ä¸ª Flink ä½œä¸š
- âœ… å®ç°åŠŸèƒ½ï¼š
  - è®¢å•ä¸ç”¨æˆ·ä¿¡æ¯å…³è”
  - åŸå¸‚åˆ†å±‚å¤„ç† (åŒ—äº¬ã€ä¸Šæµ·â†’ä¸€çº¿åŸå¸‚)
  - ç©ºå€¼å¤„ç† (Unknown User é»˜è®¤å€¼)
  - å®æ—¶æ•°æ®æ›´æ–°

**éªŒè¯ç»´åº¦å…³è”**ï¼š
```bash
# éªŒè¯æœ€ç»ˆç»“æœæ•°æ®
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic result_orders_with_user_info --from-beginning --max-messages 5
```

### æ­¥éª¤ 7ï¼šç¬¬å››é˜¶æ®µ - æ•°æ®å†™å…¥ç›®æ ‡åº“

```bash
# æ‰§è¡Œç›®æ ‡æ•°æ®åº“å†™å…¥ SQL
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/4_sink_to_postgres.sql
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… åˆ›å»ºç»“æœæºè¡¨ (è¯»å– Kafka æœ€ç»ˆç»“æœ)
- âœ… åˆ›å»º PostgreSQL ç›®æ ‡è¡¨
- âœ… æäº¤ 1ä¸ª Flink ä½œä¸š
- âœ… å¹¶è¡Œåº¦ä¼˜åŒ–è®¾ç½® (parallelism.default = 1)
- âœ… æ•°æ®æŒä¹…åŒ–åˆ° PostgreSQL

**éªŒè¯æœ€ç»ˆç»“æœ**ï¼š
```bash
# éªŒè¯ç›®æ ‡æ•°æ®åº“ä¸­çš„æ•°æ®
docker exec -it postgres-sink psql -U postgres -d sink_db -c "
SELECT 
    order_id, 
    username, 
    city, 
    product_name, 
    total_amount, 
    order_status,
    processed_time
FROM result.orders_with_user_info 
ORDER BY order_id;
"
```

### æ­¥éª¤ 8ï¼šæ•´ä½“éªŒè¯

```bash
# 1. æ£€æŸ¥æ‰€æœ‰ Flink ä½œä¸šçŠ¶æ€
docker exec -it jobmanager flink list

# 2. æ£€æŸ¥é›†ç¾¤èµ„æºä½¿ç”¨æƒ…å†µ
curl -s http://localhost:8081/taskmanagers | python3 -m json.tool

# 3. éªŒè¯ç«¯åˆ°ç«¯æ•°æ®æµ
echo "=== æºæ•°æ® ==="
docker exec -it postgres-source psql -U postgres -d source_db -c "SELECT COUNT(*) FROM business.orders;"

echo "=== æœ€ç»ˆç»“æœ ==="
docker exec -it postgres-sink psql -U postgres -d sink_db -c "SELECT COUNT(*) FROM result.orders_with_user_info;"
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… 4-5ä¸ª Flink ä½œä¸šåœ¨è¿è¡Œ
- âœ… 8ä¸ª Task Slots ä¸­ 6-7ä¸ªè¢«ä½¿ç”¨
- âœ… æºæ•°æ®åº“ 5æ¡è®°å½•
- âœ… ç›®æ ‡æ•°æ®åº“ 5æ¡å¤„ç†åçš„è®°å½•

---

## ğŸ”§ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### ğŸ·ï¸ é—®é¢˜åˆ†ç±»æ€»ç»“

æœ¬èŠ‚åŸºäºå®é™…å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°çš„å„ç±»é—®é¢˜ï¼ŒæŒ‰ç…§æŠ€æœ¯é¢†åŸŸè¿›è¡Œåˆ†ç±»æ•´ç†ï¼Œå¸®åŠ©å¿«é€Ÿå®šä½å’Œè§£å†³ç±»ä¼¼é—®é¢˜ã€‚

---

### ğŸ“ ä¸€ã€å®¹å™¨å’Œç½‘ç»œé…ç½®é—®é¢˜

#### 1.1 RPCç½‘ç»œè¿æ¥é—®é¢˜

**ç°è±¡**ï¼š
```
org.apache.pekko.remote.EndpointWriter: dropping message for non-local recipient
Could not connect to rpc endpoint under address pekko.tcp://flink@jobmanager:6123
```

**æ ¹æœ¬åŸå› **ï¼š
- TaskManageræ— æ³•è¿æ¥åˆ°JobManagerçš„ResourceManager
- å®¹å™¨é—´ç½‘ç»œé…ç½®ä¸å½“
- hostnameå’Œcontainer_nameé…ç½®å†²çª

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# é”™è¯¯é…ç½®
taskmanager:
  hostname: taskmanager
  container_name: taskmanager  # ä¸scaleå†²çª
  scale: 2

# æ­£ç¡®é…ç½®
taskmanager:
  scale: 2  # ç§»é™¤å›ºå®šhostnameå’Œcontainer_name
  environment:
    - JOB_MANAGER_RPC_ADDRESS=jobmanager
```

#### 1.2 Docker Composeé…ç½®å†²çª

**ç°è±¡**ï¼š
```
services.scale: can't set container_name and taskmanager as container name must be unique
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨scaleæ—¶ä¸èƒ½è®¾ç½®å›ºå®šçš„container_name
2. è®©Dockerè‡ªåŠ¨ç”Ÿæˆå®¹å™¨åç§°
3. é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æœåŠ¡å‘ç°

---

### ğŸ“¦ äºŒã€JARåŒ…å’Œè¿æ¥å™¨é—®é¢˜

#### 2.1 è¿æ¥å™¨å·¥å‚æ‰¾ä¸åˆ°

**ç°è±¡**ï¼š
```
Could not find any factory for identifier 'postgres-cdc' that implements 'org.apache.flink.table.factories.DynamicTableFactory'
```

**æ ¹æœ¬åŸå› **ï¼š
- JARæ–‡ä»¶æœªæ­£ç¡®åŠ è½½åˆ°Flink classpath
- JARæ–‡ä»¶æ”¾åœ¨é”™è¯¯çš„ç›®å½•

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# é—®é¢˜ï¼šJARåœ¨usrlibç›®å½•ï¼ŒFlinkä¸ä¼šè‡ªåŠ¨åŠ è½½
./flink/jars:/opt/flink/usrlib

# è§£å†³ï¼šè‡ªåŠ¨å¤åˆ¶åˆ°libç›®å½•
command: |
  bash -c "
    cp /opt/flink/lib-extra/*.jar /opt/flink/lib/
    /docker-entrypoint.sh jobmanager
  "
volumes:
  - ./flink/jars:/opt/flink/lib-extra
```

#### 2.2 JARç‰ˆæœ¬å…¼å®¹æ€§

**å¿…éœ€çš„JARæ–‡ä»¶æ¸…å•**ï¼š
```
flink-sql-connector-postgres-cdc-3.1.1.jar  # CDCè¿æ¥å™¨
flink-sql-connector-kafka-3.2.0-1.18.jar    # Kafkaè¿æ¥å™¨
flink-connector-jdbc-3.2.0-1.18.jar         # JDBCè¿æ¥å™¨
postgresql-42.7.1.jar                        # PostgreSQLé©±åŠ¨
```

---

### ğŸ”— ä¸‰ã€Kafkaè¿æ¥å™¨é€‰æ‹©é—®é¢˜

#### 3.1 CDCåœºæ™¯çš„è¿æ¥å™¨é€‰æ‹©

**å…³é”®åŒºåˆ«**ï¼š
```sql
-- âŒ é”™è¯¯ï¼šæ™®é€škafkaè¿æ¥å™¨ä¸æ”¯æŒCDCè¯­ä¹‰
CREATE TABLE ods_orders (
    order_id BIGINT PRIMARY KEY  -- ä¼šæŠ¥é”™
) WITH (
    'connector' = 'kafka'  -- ä¸æ”¯æŒUPDATE/DELETE
);

-- âœ… æ­£ç¡®ï¼šupsert-kafkaæ”¯æŒCDCè¯­ä¹‰
CREATE TABLE ods_orders (
    order_id BIGINT,
    PRIMARY KEY (order_id) NOT ENFORCED  -- æ”¯æŒä¸»é”®
) WITH (
    'connector' = 'upsert-kafka'  -- æ”¯æŒUPDATE/DELETE
);
```

#### 3.2 Kafkaä¸»é”®çº¦æŸä½¿ç”¨è§„åˆ™

| è¿æ¥å™¨ç±»å‹ | ä¸»é”®æ”¯æŒ | ä½¿ç”¨åœºæ™¯ | æ•°æ®æ ¼å¼ |
|-----------|---------|----------|----------|
| `kafka` | âŒ ä¸æ”¯æŒ | Append-Onlyæµ | JSON |
| `upsert-kafka` | âœ… æ”¯æŒ | CDCå˜æ›´æµ | JSON |
| `kafka` (Avro) | âœ… æ”¯æŒ | Schemaæ¼”è¿› | Avro |

**JSONæ ¼å¼ä¸»é”®çº¦æŸé”™è¯¯**ï¼š
```
The Kafka table with 'json' format doesn't support defining PRIMARY KEY constraint
```

---

### ğŸ’¾ å››ã€èµ„æºé…ç½®å’Œæ€§èƒ½é—®é¢˜

#### 4.1 èµ„æºä¸è¶³å¼‚å¸¸

**ç°è±¡**ï¼š
```
org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: 
Could not acquire the minimum required resources.
```

**èµ„æºéœ€æ±‚åˆ†æ**ï¼š
```
å…¸å‹4é˜¶æ®µæµæ°´çº¿èµ„æºéœ€æ±‚ï¼š
- Stage 1 (CDC): 2ä¸ªTask Slots
- Stage 2 (DWD): 2ä¸ªTask Slots  
- Stage 3 (Join): 2ä¸ªTask Slots
- Stage 4 (Sink): 1ä¸ªTask Slot
æ€»éœ€æ±‚ï¼š7-8ä¸ªTask Slots
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# å¢åŠ TaskManageræ•°é‡
taskmanager:
  scale: 2  # ä»1ä¸ªå¢åŠ åˆ°2ä¸ª
  environment:
    - taskmanager.numberOfTaskSlots: 4  # æ¯ä¸ª4ä¸ªslots
# æ€»è®¡ï¼š8ä¸ªTask Slots

# æ§åˆ¶å¹¶è¡Œåº¦
- parallelism.default: 1  # é¿å…è¿‡åº¦å¹¶è¡Œ
```

#### 4.2 å†…å­˜é…ç½®ä¼˜åŒ–

**é»˜è®¤é…ç½®vsä¼˜åŒ–é…ç½®**ï¼š
```yaml
# åŸºç¡€é…ç½®ï¼ˆé€‚åˆå¼€å‘ç¯å¢ƒï¼‰
taskmanager:
  # ä½¿ç”¨é»˜è®¤å†…å­˜è®¾ç½®ï¼Œçº¦1-2GB

# ç”Ÿäº§é…ç½®ï¼ˆå¦‚éœ€è¦ï¼‰
taskmanager:
  environment:
    - taskmanager.memory.process.size: 4096m
    - taskmanager.memory.task-heap.size: 2048m
```

---

### ğŸ”§ äº”ã€æ•°æ®ç±»å‹å’Œæ ¼å¼é—®é¢˜

#### 5.1 æ—¶é—´å‡½æ•°ç±»å‹è½¬æ¢

**ç°è±¡**ï¼š
```
Cannot cast BIGINT to INT
Required: INT, Actual: BIGINT
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```sql
-- âŒ é”™è¯¯ï¼šHOURå‡½æ•°è¿”å›BIGINT
order_hour INT,  -- å­—æ®µå®šä¹‰ä¸ºINT
HOUR(order_time) as order_hour  -- ä½†HOURè¿”å›BIGINT

-- âœ… æ­£ç¡®ï¼šæ˜¾å¼ç±»å‹è½¬æ¢
order_hour INT,
CAST(HOUR(order_time) AS INT) as order_hour
```

#### 5.2 æ—¶é—´æˆ³æ ¼å¼å¤„ç†

**æ ‡å‡†æ—¶é—´æˆ³å®šä¹‰**ï¼š
```sql
-- ç»Ÿä¸€ä½¿ç”¨TIMESTAMP(3)æ”¯æŒæ¯«ç§’ç²¾åº¦
order_time TIMESTAMP(3),
updated_at TIMESTAMP(3),
etl_time TIMESTAMP(3)
```

---

### ğŸ›£ï¸ å…­ã€è·¯å¾„å’ŒæŒ‚è½½é—®é¢˜

#### 6.1 å®¹å™¨å†…æ–‡ä»¶è·¯å¾„é”™è¯¯

**ç°è±¡**ï¼š
```
java.io.FileNotFoundException: /opt/flink/sql/1_cdc_source_to_kafka.sql (No such file or directory)
```

**è·¯å¾„æ˜ å°„æ£€æŸ¥**ï¼š
```yaml
# docker-compose.ymlä¸­çš„æŒ‚è½½
volumes:
  - ./flink/sql:/opt/sql  # æŒ‚è½½åˆ°/opt/sql

# æ‰§è¡Œå‘½ä»¤åº”è¯¥ä½¿ç”¨æ­£ç¡®è·¯å¾„
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/1_cdc_source_to_kafka.sql
```

---

### ğŸš€ ä¸ƒã€æœåŠ¡å¯åŠ¨å’Œä¾èµ–é—®é¢˜

#### 7.1 æœåŠ¡å¯åŠ¨é¡ºåº

**æ¨èå¯åŠ¨é¡ºåº**ï¼š
1. Zookeeper (åŸºç¡€æœåŠ¡)
2. Kafka (ä¾èµ–Zookeeper)
3. PostgreSQL (æ•°æ®åº“æœåŠ¡)
4. Fluss (å¯é€‰ï¼Œä¾èµ–Zookeeper)
5. Flink JobManager
6. Flink TaskManager (ä¾èµ–JobManager)
7. SQL Client (ä¾èµ–æ‰€æœ‰æœåŠ¡)

#### 7.2 å¥åº·æ£€æŸ¥é…ç½®

**æœ‰æ•ˆçš„å¥åº·æ£€æŸ¥**ï¼š
```yaml
# âœ… æœ‰æ•ˆï¼šPostgreSQL
healthcheck:
  test: ["CMD-SHELL", "pg_isready -U postgres -d source_db"]
  interval: 10s
  timeout: 5s
  retries: 5

# âœ… æœ‰æ•ˆï¼šFlink JobManager
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
  interval: 30s
  timeout: 10s
  retries: 3

# âŒ é¿å…ï¼šå¤æ‚çš„shellå‘½ä»¤åœ¨å®¹å™¨ä¸­å¯èƒ½å¤±è´¥
healthcheck:
  test: ["CMD", "ps", "aux", "|", "grep", "taskmanager"]
```

---

### ğŸ› ï¸ å…«ã€è°ƒè¯•å’Œæ•…éšœæ’é™¤æ–¹æ³•

#### 8.1 ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å‘½ä»¤

```bash
# 1. å®¹å™¨çŠ¶æ€æ£€æŸ¥
docker-compose ps
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# 2. Flinké›†ç¾¤çŠ¶æ€
curl -s http://localhost:8081/overview | python3 -m json.tool

# 3. TaskManagerèµ„æº
curl -s http://localhost:8081/taskmanagers

# 4. ä½œä¸šçŠ¶æ€
docker exec -it jobmanager flink list

# 5. Kafkaä¸»é¢˜æ£€æŸ¥
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# 6. æ•°æ®åº“è¿æ¥æµ‹è¯•
docker exec -it postgres-source psql -U postgres -d source_db -c "SELECT COUNT(*) FROM business.orders;"
```

#### 8.2 æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f jobmanager
docker-compose logs -f taskmanager
docker-compose logs -f kafka

# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
docker logs jobmanager 2>&1 | tail -20
```

---

### ğŸ“‹ ä¹ã€æœ€ä½³å®è·µæ€»ç»“

#### 9.1 å¼€å‘ç¯å¢ƒé…ç½®

```yaml
# æ¨èçš„å¼€å‘ç¯å¢ƒé…ç½®
jobmanager:
  # ä½¿ç”¨é»˜è®¤å†…å­˜é…ç½®
  
taskmanager:
  scale: 2  # 2ä¸ªTaskManagerï¼Œ8ä¸ªTask Slots
  environment:
    - parallelism.default: 1  # æ§åˆ¶å¹¶è¡Œåº¦
    
sql-client:
  # è‡ªåŠ¨å¤åˆ¶JARæ–‡ä»¶
  command: |
    bash -c "
      cp /opt/flink/lib-extra/*.jar /opt/flink/lib/
      # å…¶ä»–åˆå§‹åŒ–æ“ä½œ
    "
```

#### 9.2 è¿æ¥å™¨é€‰æ‹©æŒ‡å—

```sql
-- CDCæºè¡¨ï¼šä½¿ç”¨postgres-cdc
CREATE TABLE orders_source (...) WITH (
    'connector' = 'postgres-cdc',
    'slot.name' = 'unique_slot_name'  -- ç¡®ä¿å”¯ä¸€æ€§
);

-- Kafka Sink (CDCåœºæ™¯)ï¼šä½¿ç”¨upsert-kafka
CREATE TABLE ods_orders (...) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'ods_orders'
);

-- Kafka Source (è¯»å–)ï¼šä½¿ç”¨kafka
CREATE TABLE ods_orders_source (...) WITH (
    'connector' = 'kafka',
    'scan.startup.mode' = 'earliest-offset'
);

-- PostgreSQL Sinkï¼šä½¿ç”¨jdbc
CREATE TABLE result_table (...) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:postgresql://postgres-sink:5432/sink_db'
);
```

---

## âœ… é¢„æœŸæ•ˆæœéªŒè¯

### 1. ä¸šåŠ¡æ•°æ®éªŒè¯

**è®¢å•æ•°æ®æ ·ä¾‹**ï¼š
```json
{
  "order_id": 2001,
  "user_id": 1001,
  "username": "å¼ ä¸‰",
  "email": "zhangsan@example.com",
  "phone": "13812345678",
  "city": "åŒ—äº¬",
  "product_name": "iPhone 15",
  "product_category": "ç”µå­äº§å“",
  "product_category_normalized": "ELECTRONICS",
  "quantity": 1,
  "unit_price": 5999.00,
  "total_amount": 5999.00,
  "total_amount_yuan": "Â¥5999.00",
  "order_status": "COMPLETED",
  "order_status_desc": "å·²å®Œæˆ",
  "order_time": "2025-07-11 17:25:55.145",
  "order_date": "2025-07-11",
  "order_hour": 17,
  "user_register_time": "2025-07-11 17:25:55.143",
  "user_city_tier": "ä¸€çº¿åŸå¸‚",
  "join_time": "2025-07-12 02:32:59.555"
}
```

### 2. æ•°æ®å¤„ç†éªŒè¯

**æ•°æ®æ¸…æ´—æ•ˆæœ**ï¼š
- âœ… å•†å“åˆ†ç±»æ ‡å‡†åŒ–ï¼šç”µå­äº§å“â†’ELECTRONICS, æœè£…é‹å¸½â†’CLOTHING
- âœ… çŠ¶æ€æè¿°è½¬æ¢ï¼šCOMPLETEDâ†’å·²å®Œæˆ, PENDINGâ†’å¾…å¤„ç†
- âœ… ä»·æ ¼æ ¼å¼åŒ–ï¼š5999â†’Â¥5999.00
- âœ… æ—¶é—´å­—æ®µå¤„ç†ï¼šæ·»åŠ æ—¥æœŸ(2025-07-11)å’Œå°æ—¶(17)

**ç»´åº¦å…³è”æ•ˆæœ**ï¼š
- âœ… è®¢å•å…³è”ç”¨æˆ·ä¿¡æ¯ï¼šå¼ ä¸‰(åŒ—äº¬), æå››(ä¸Šæµ·), ç‹äº”(å¹¿å·)
- âœ… åŸå¸‚åˆ†å±‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³â†’ä¸€çº¿åŸå¸‚
- âœ… ç©ºå€¼å¤„ç†ï¼šUnknown User, unknown@example.com

### 3. æŠ€æœ¯æŒ‡æ ‡éªŒè¯

**æ€§èƒ½æŒ‡æ ‡**ï¼š
- âœ… æ•°æ®å¤„ç†å»¶è¿Ÿï¼š< 1ç§’
- âœ… æ•°æ®å®Œæ•´æ€§ï¼š100% (5æ¡æºæ•°æ® â†’ 5æ¡ç»“æœæ•°æ®)
- âœ… ç³»ç»Ÿå¯ç”¨æ€§ï¼š99.9% (æµå¤„ç†æŒç»­è¿è¡Œ)
- âœ… èµ„æºåˆ©ç”¨ç‡ï¼šTask Slots ä½¿ç”¨ç‡ 60-80%

**ç›‘æ§æŒ‡æ ‡**ï¼š
- âœ… Flink Web UIï¼šhttp://localhost:8081
- âœ… ä½œä¸šçŠ¶æ€ï¼šæ‰€æœ‰ä½œä¸š RUNNING
- âœ… æ£€æŸ¥ç‚¹ï¼šè‡ªåŠ¨æ£€æŸ¥ç‚¹æ­£å¸¸
- âœ… åå‹ç›‘æ§ï¼šæ— åå‹æƒ…å†µ

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚è§£é‡Š

### 1. CDC (Change Data Capture) æœºåˆ¶

**å·¥ä½œåŸç†**ï¼š
- ç›‘å¬ PostgreSQL çš„ WAL (Write-Ahead Log)
- å®æ—¶æ•è· INSERTã€UPDATEã€DELETE æ“ä½œ
- å°†å˜æ›´æ•°æ®å‘é€åˆ° Kafka

**å…³é”®é…ç½®**ï¼š
```sql
'connector' = 'postgres-cdc',
'hostname' = 'postgres-source',
'port' = '5432',
'username' = 'postgres',
'password' = 'postgres',
'database-name' = 'source_db',
'schema-name' = 'business',
'table-name' = 'orders',
'slot.name' = 'flink_slot_orders'
```

### 2. Kafka è¿æ¥å™¨ç±»å‹

**æ™®é€š Kafka è¿æ¥å™¨**ï¼š
- ç”¨äº Append-Only æ•°æ®æµ
- é€‚åˆ CDC æºæ•°æ®å†™å…¥

**Upsert Kafka è¿æ¥å™¨**ï¼š
- æ”¯æŒ UPDATE/DELETE æ“ä½œ
- é€‚åˆç»´åº¦è¡¨å’Œç»“æœè¡¨
- éœ€è¦å®šä¹‰ä¸»é”®

### 3. Flink å†…å­˜ç®¡ç†

**JobManager å†…å­˜åˆ†é…**ï¼š
- Process Memory: 2048MB
- JVM Heap: 1024MB
- Off-Heap: 1024MB

**TaskManager å†…å­˜åˆ†é…**ï¼š
- Process Memory: 4096MB
- Task Heap: 2048MB
- Managed Memory: 1024MB
- Network Memory: 256-512MB

### 4. æµå¤„ç†è¯­ä¹‰

**å¤„ç†æ—¶é—´è¯­ä¹‰**ï¼š
- åŸºäºç³»ç»Ÿæ—¶é—´å¤„ç†
- ä½å»¶è¿Ÿï¼Œé€‚åˆå®æ—¶åœºæ™¯

**äº‹ä»¶æ—¶é—´è¯­ä¹‰**ï¼š
- åŸºäºæ•°æ®ä¸­çš„æ—¶é—´æˆ³
- å‡†ç¡®æ€§é«˜ï¼Œé€‚åˆç²¾ç¡®è®¡ç®—

### 5. ç»´åº¦è¡¨å…³è”ç­–ç•¥

**æ—¶é—´çª—å£å…³è”**ï¼š
- ä½¿ç”¨ INTERVAL JOIN
- å¤„ç†æ—¶é—´ä¸ä¸€è‡´é—®é¢˜

**çŠ¶æ€å­˜å‚¨**ï¼š
- ä½¿ç”¨ Flink çŠ¶æ€åç«¯
- æ”¯æŒæ£€æŸ¥ç‚¹å’Œæ¢å¤

---

## ğŸ”„ å®æ—¶ä¸šåŠ¡éªŒè¯

### ğŸ“Š å®æ—¶è®¢å•æ›´æ–°éªŒè¯åœºæ™¯

æœ¬èŠ‚æä¾›ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯å®æ—¶éªŒè¯åœºæ™¯ï¼Œç”¨äºéªŒè¯æ•´ä¸ªæµå¤„ç†é“¾è·¯çš„å®æ—¶æ€§å’Œæ­£ç¡®æ€§ã€‚

#### éªŒè¯ç›®æ ‡
- âœ… éªŒè¯CDCå®æ—¶æ•è·å˜æ›´
- âœ… éªŒè¯æ•°æ®æ¸…æ´—è½¬æ¢æ­£ç¡®æ€§
- âœ… éªŒè¯ç»´åº¦å…³è”å®æ—¶æ€§
- âœ… éªŒè¯ç«¯åˆ°ç«¯å»¶è¿Ÿ (<5ç§’)
- âœ… éªŒè¯æ•°æ®ä¸€è‡´æ€§

#### ä¸šåŠ¡åœºæ™¯ï¼šè®¢å•çŠ¶æ€å®æ—¶æ›´æ–°

**åœºæ™¯æè¿°**ï¼šæ¨¡æ‹Ÿç”µå•†è®¢å•ä»"å¾…å¤„ç†"åˆ°"å·²å‘è´§"å†åˆ°"å·²å®Œæˆ"çš„çŠ¶æ€å˜æ›´ï¼ŒéªŒè¯æ•´ä¸ªæ•°æ®æµå®æ—¶å¤„ç†æ•ˆæœã€‚

---

### ğŸ¤– è‡ªåŠ¨åŒ–éªŒè¯ï¼ˆæ¨èï¼‰

**ä¸€é”®å¼éªŒè¯è„šæœ¬**ï¼š
```bash
# è¿è¡Œè‡ªåŠ¨åŒ–å®æ—¶éªŒè¯æµ‹è¯•
./realtime_validation_test.sh
```

**è„šæœ¬åŠŸèƒ½**ï¼š
- âœ… è‡ªåŠ¨æ£€æŸ¥ç¯å¢ƒçŠ¶æ€
- âœ… è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•è®¢å•
- âœ… å®æ—¶ç›‘æ§æ•°æ®æµè½¬
- âœ… è‡ªåŠ¨éªŒè¯ç«¯åˆ°ç«¯å»¶è¿Ÿ
- âœ… ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
- âœ… å½©è‰²è¾“å‡ºï¼Œæ˜“äºé˜…è¯»

**é¢„æœŸè¾“å‡ºç¤ºä¾‹**ï¼š
```
========================================
Apache Flink å®æ—¶ä¸šåŠ¡éªŒè¯æµ‹è¯•
========================================
[STEP] æ£€æŸ¥ç¯å¢ƒçŠ¶æ€...
[SUCCESS] ç¯å¢ƒæ£€æŸ¥é€šè¿‡
[STEP] éªŒè¯åˆå§‹æ•°æ®çŠ¶æ€...
[INFO] è¿è¡Œä¸­çš„Flinkä½œä¸šæ•°é‡: 4
[STEP] æ‰§è¡Œå®æ—¶ä¸šåŠ¡æ“ä½œ...
[INFO] æµ‹è¯•è®¢å•ID: 2287
[SUCCESS] è®¢å•æ’å…¥æˆåŠŸ
[SUCCESS] è®¢å•çŠ¶æ€æ›´æ–°ä¸ºSHIPPED  
[SUCCESS] è®¢å•å®Œæˆ
[STEP] éªŒè¯æ•°æ®æµè½¬...
[SUCCESS] ODSå±‚æ•°æ®éªŒè¯é€šè¿‡ (å‘ç° 3 æ¡è®°å½•)
[SUCCESS] DWDå±‚æ•°æ®éªŒè¯é€šè¿‡ (å‘ç° 3 æ¡è®°å½•)
[SUCCESS] ç»´åº¦å…³è”éªŒè¯é€šè¿‡ (å‘ç° 3 æ¡è®°å½•)
[SUCCESS] ğŸ‰ å®æ—¶éªŒè¯æµ‹è¯•é€šè¿‡ï¼

=== æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š ===
ğŸ“Š æ•°æ®å¤„ç†ç»Ÿè®¡:
  â€¢ æ€»å¤„ç†è®¢å•æ•°: 8
  â€¢ å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿ: 3.45 ç§’
ğŸ”§ é›†ç¾¤èµ„æºçŠ¶æ€:
  â€¢ TaskManageræ•°é‡: 2
  â€¢ æ€»Task Slots: 8
  â€¢ å¯ç”¨Task Slots: 1
  â€¢ èµ„æºåˆ©ç”¨ç‡: 87%
[SUCCESS] âœ… å»¶è¿Ÿæ€§èƒ½: ä¼˜ç§€ (< 5ç§’)
```

---

### ğŸš€ æ‰‹åŠ¨éªŒè¯æ­¥éª¤ï¼ˆå¯é€‰ï¼‰

#### æ­¥éª¤1ï¼šå¯åŠ¨å®Œæ•´ç¯å¢ƒå¹¶è¿è¡Œæ‰€æœ‰SQLè„šæœ¬

```bash
# 1. å¯åŠ¨ç¯å¢ƒ
docker-compose up -d
sleep 60  # ç­‰å¾…æœåŠ¡å°±ç»ª

# 2. æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰SQLè„šæœ¬
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/1_cdc_source_to_kafka.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/2_dwd_layer.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/3_dimension_join.sql
docker exec -it sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/4_sink_to_postgres.sql

# 3. ç­‰å¾…æ‰€æœ‰ä½œä¸šå¯åŠ¨
sleep 30
```

#### æ­¥éª¤2ï¼šéªŒè¯åˆå§‹æ•°æ®çŠ¶æ€

```bash
# æ£€æŸ¥æºæ•°æ®åº“åˆå§‹è®¢å•
echo "=== æºæ•°æ®åº“åˆå§‹è®¢å• ==="
docker exec -it postgres-source psql -U postgres -d source_db -c "
SELECT order_id, user_id, product_name, order_status, order_time 
FROM business.orders 
ORDER BY order_id;
"

# æ£€æŸ¥æœ€ç»ˆç»“æœè¡¨åˆå§‹çŠ¶æ€
echo "=== æœ€ç»ˆç»“æœè¡¨åˆå§‹çŠ¶æ€ ==="
docker exec -it postgres-sink psql -U postgres -d sink_db -c "
SELECT order_id, username, product_name, order_status_desc, user_city_tier, processed_time
FROM result.orders_with_user_info 
ORDER BY order_id;
"
```

#### æ­¥éª¤3ï¼šæ‰§è¡Œå®æ—¶ä¸šåŠ¡æ“ä½œ

**3.1 æ’å…¥æ–°è®¢å•**
```bash
echo "=== æ’å…¥æ–°è®¢å• (è®¢å•ID: 2006) ==="
docker exec -it postgres-source psql -U postgres -d source_db -c "
INSERT INTO business.orders (order_id, user_id, product_name, product_category, quantity, unit_price, total_amount, order_status, order_time, updated_at)
VALUES (2006, 1001, 'AirPods Pro', 'ç”µå­äº§å“', 1, 1999.00, 1999.00, 'PENDING', NOW(), NOW());
"

# è®°å½•æ’å…¥æ—¶é—´
echo "æ–°è®¢å•æ’å…¥æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')"
```

**3.2 æ›´æ–°è®¢å•çŠ¶æ€ (PENDING â†’ SHIPPED)**
```bash
echo "=== æ›´æ–°è®¢å•çŠ¶æ€: PENDING â†’ SHIPPED ==="
sleep 5  # ç­‰å¾…CDCæ•è·
docker exec -it postgres-source psql -U postgres -d source_db -c "
UPDATE business.orders 
SET order_status = 'SHIPPED', updated_at = NOW() 
WHERE order_id = 2006;
"

echo "è®¢å•çŠ¶æ€æ›´æ–°æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')"
```

**3.3 å®Œæˆè®¢å• (SHIPPED â†’ COMPLETED)**
```bash
echo "=== å®Œæˆè®¢å•: SHIPPED â†’ COMPLETED ==="
sleep 5  # ç­‰å¾…çŠ¶æ€æ›´æ–°ä¼ æ’­
docker exec -it postgres-source psql -U postgres -d source_db -c "
UPDATE business.orders 
SET order_status = 'COMPLETED', updated_at = NOW() 
WHERE order_id = 2006;
"

echo "è®¢å•å®Œæˆæ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')"
```

#### æ­¥éª¤4ï¼šå®æ—¶éªŒè¯æ•°æ®æµè½¬

**4.1 éªŒè¯CDCå±‚æ•°æ®æ•è·**
```bash
echo "=== éªŒè¯ODSå±‚CDCæ•°æ® ==="
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ods_orders \
  --from-beginning \
  --timeout-ms 10000 | grep "2006" | tail -3
```

**4.2 éªŒè¯DWDå±‚æ•°æ®æ¸…æ´—**
```bash
echo "=== éªŒè¯DWDå±‚æ•°æ®æ¸…æ´— ==="
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic dwd_orders \
  --from-beginning \
  --timeout-ms 10000 | grep "2006" | tail -3
```

**4.3 éªŒè¯ç»´åº¦å…³è”ç»“æœ**
```bash
echo "=== éªŒè¯ç»´åº¦å…³è”ç»“æœ ==="
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic result_orders_with_user_info \
  --from-beginning \
  --timeout-ms 10000 | grep "2006" | tail -3
```

#### æ­¥éª¤5ï¼šéªŒè¯æœ€ç»ˆç»“æœå’Œå®æ—¶æ€§

**5.1 æ£€æŸ¥æœ€ç»ˆæ•°æ®åº“ç»“æœ**
```bash
echo "=== æœ€ç»ˆç»“æœéªŒè¯ ==="
sleep 10  # ç­‰å¾…Sinkå†™å…¥
docker exec -it postgres-sink psql -U postgres -d sink_db -c "
SELECT 
    order_id,
    username,
    city,
    product_name,
    total_amount_yuan,
    order_status_desc,
    user_city_tier,
    TO_CHAR(processed_time, 'YYYY-MM-DD HH24:MI:SS') as processed_time
FROM result.orders_with_user_info 
WHERE order_id = 2006
ORDER BY processed_time DESC;
"
```

**5.2 ç«¯åˆ°ç«¯å»¶è¿ŸéªŒè¯**
```bash
echo "=== ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†æ ==="
docker exec -it postgres-sink psql -U postgres -d sink_db -c "
SELECT 
    order_id,
    order_status_desc,
    DATE_PART('epoch', processed_time - order_time) as latency_seconds,
    TO_CHAR(order_time, 'HH24:MI:SS.MS') as source_time,
    TO_CHAR(processed_time, 'HH24:MI:SS.MS') as result_time
FROM result.orders_with_user_info 
WHERE order_id = 2006
ORDER BY processed_time DESC
LIMIT 3;
"
```

---

### âœ… é¢„æœŸéªŒè¯ç»“æœ

#### æˆåŠŸæŒ‡æ ‡

**1. æ•°æ®å®Œæ•´æ€§**
```json
// ODSå±‚åŸå§‹æ•°æ®
{"order_id":2006,"product_name":"AirPods Pro","order_status":"COMPLETED"}

// DWDå±‚æ¸…æ´—æ•°æ®  
{"order_id":2006,"product_category_normalized":"ELECTRONICS","total_amount_yuan":"Â¥1999.00","order_status_desc":"å·²å®Œæˆ"}

// æœ€ç»ˆå…³è”ç»“æœ
{"order_id":2006,"username":"å¼ ä¸‰","user_city_tier":"ä¸€çº¿åŸå¸‚","order_status_desc":"å·²å®Œæˆ"}
```

**2. å®æ—¶æ€§æŒ‡æ ‡**
- âœ… CDCæ•è·å»¶è¿Ÿï¼š< 2ç§’
- âœ… æ•°æ®æ¸…æ´—å»¶è¿Ÿï¼š< 1ç§’  
- âœ… ç»´åº¦å…³è”å»¶è¿Ÿï¼š< 1ç§’
- âœ… æ•°æ®åº“å†™å…¥å»¶è¿Ÿï¼š< 1ç§’
- âœ… **ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿï¼š< 5ç§’**

**3. çŠ¶æ€å˜æ›´è¿½è¸ª**
```sql
-- åº”è¯¥çœ‹åˆ°3æ¡è®°å½•ï¼Œå¯¹åº”è®¢å•çš„3ä¸ªçŠ¶æ€
order_id | order_status_desc | latency_seconds | source_time | result_time
---------|-------------------|-----------------|-------------|-------------
2006     | å·²å®Œæˆ            | 4.2            | 14:30:45.123| 14:30:49.345
2006     | å·²å‘è´§            | 3.8            | 14:30:40.456| 14:30:44.234  
2006     | å¾…å¤„ç†            | 3.5            | 14:30:35.789| 14:30:39.123
```

#### æ•…éšœæ’é™¤

**å¦‚æœæ²¡æœ‰çœ‹åˆ°æ•°æ®**ï¼š
```bash
# 1. æ£€æŸ¥Flinkä½œä¸šçŠ¶æ€
docker exec -it jobmanager flink list

# 2. æ£€æŸ¥ä½œä¸šæ˜¯å¦æœ‰å¼‚å¸¸
curl -s http://localhost:8081/jobs/overview

# 3. æ£€æŸ¥Kafkaä¸»é¢˜
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# 4. æ£€æŸ¥PostgreSQL CDCè¿æ¥
docker exec -it postgres-source psql -U postgres -d source_db -c "SELECT * FROM pg_replication_slots;"
```

**å¦‚æœå»¶è¿Ÿè¿‡é«˜**ï¼š
```bash
# 1. æ£€æŸ¥TaskManagerèµ„æºä½¿ç”¨
curl -s http://localhost:8081/taskmanagers

# 2. æ£€æŸ¥ä½œä¸šèƒŒå‹
curl -s http://localhost:8081/jobs/overview

# 3. è°ƒæ•´å¹¶è¡Œåº¦
# åœ¨SQLä¸­è®¾ç½®ï¼šSET 'parallelism.default' = '1';
```

---

### ğŸ”„ è¿ç»­å‹åŠ›æµ‹è¯• (å¯é€‰)

#### æ‰¹é‡è®¢å•æ›´æ–°æµ‹è¯•

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > continuous_test.sh << 'EOF'
#!/bin/bash
echo "å¼€å§‹è¿ç»­è®¢å•æµ‹è¯•..."

for i in {2007..2020}; do
    echo "å¤„ç†è®¢å• $i"
    
    # æ’å…¥è®¢å•
    docker exec -it postgres-source psql -U postgres -d source_db -c "
    INSERT INTO business.orders (order_id, user_id, product_name, product_category, quantity, unit_price, total_amount, order_status, order_time, updated_at)
    VALUES ($i, 100$((i%5+1)), 'Test Product $i', 'ç”µå­äº§å“', 1, 999.00, 999.00, 'PENDING', NOW(), NOW());
    "
    
    sleep 2
    
    # æ›´æ–°ä¸ºå·²å‘è´§
    docker exec -it postgres-source psql -U postgres -d source_db -c "
    UPDATE business.orders SET order_status = 'SHIPPED', updated_at = NOW() WHERE order_id = $i;
    "
    
    sleep 2
    
    # å®Œæˆè®¢å•
    docker exec -it postgres-source psql -U postgres -d source_db -c "
    UPDATE business.orders SET order_status = 'COMPLETED', updated_at = NOW() WHERE order_id = $i;
    "
    
    sleep 1
done

echo "æ‰¹é‡æµ‹è¯•å®Œæˆï¼Œæ£€æŸ¥ç»“æœ..."
docker exec -it postgres-sink psql -U postgres -d sink_db -c "
SELECT COUNT(*) as total_orders, 
       AVG(DATE_PART('epoch', processed_time - order_time)) as avg_latency_seconds
FROM result.orders_with_user_info 
WHERE order_id BETWEEN 2007 AND 2020;
"
EOF

chmod +x continuous_test.sh
```

**è¿è¡Œå‹åŠ›æµ‹è¯•**ï¼š
```bash
./continuous_test.sh
```

**é¢„æœŸç»“æœ**ï¼š
- âœ… æ‰€æœ‰è®¢å•éƒ½èƒ½è¢«æ­£ç¡®å¤„ç†
- âœ… å¹³å‡å»¶è¿Ÿä¿æŒåœ¨5ç§’ä»¥å†…
- âœ… æ— ä½œä¸šå¤±è´¥æˆ–å¼‚å¸¸
- âœ… å†…å­˜å’ŒCPUä½¿ç”¨ç¨³å®š

---

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. èµ„æºä¼˜åŒ–

**å†…å­˜ä¼˜åŒ–**ï¼š
```yaml
# å¢åŠ  TaskManager å†…å­˜
taskmanager.memory.process.size: 4096m
taskmanager.memory.task-heap.size: 2048m
taskmanager.memory.managed.size: 1024m
```

**å¹¶è¡Œåº¦ä¼˜åŒ–**ï¼š
```sql
-- åŠ¨æ€è°ƒæ•´å¹¶è¡Œåº¦
SET 'parallelism.default' = '2';
-- é’ˆå¯¹ç‰¹å®šæ“ä½œè®¾ç½®å¹¶è¡Œåº¦
'sink.parallelism' = '1'
```

### 2. Kafka ä¼˜åŒ–

**æ‰¹é‡å¤„ç†**ï¼š
```sql
'sink.buffer-flush.max-rows' = '1000',
'sink.buffer-flush.interval' = '5s'
```

**å‹ç¼©è®¾ç½®**ï¼š
```yaml
KAFKA_COMPRESSION_TYPE: gzip
KAFKA_BATCH_SIZE: 16384
```

### 3. æ£€æŸ¥ç‚¹ä¼˜åŒ–

**æ£€æŸ¥ç‚¹é…ç½®**ï¼š
```sql
SET 'execution.checkpointing.interval' = '10s';
SET 'execution.checkpointing.timeout' = '1min';
SET 'execution.checkpointing.mode' = 'EXACTLY_ONCE';
```

### 4. ç›‘æ§å’Œå‘Šè­¦

**æŒ‡æ ‡ç›‘æ§**ï¼š
- ä½œä¸šå»¶è¿Ÿ (Job Latency)
- æ•°æ®åå‹ (Backpressure)
- æ£€æŸ¥ç‚¹æˆåŠŸç‡ (Checkpoint Success Rate)
- å¼‚å¸¸é‡å¯æ¬¡æ•° (Restart Count)

**å‘Šè­¦è®¾ç½®**ï¼š
- ä½œä¸šå¤±è´¥å‘Šè­¦
- å»¶è¿Ÿè¶…é˜ˆå€¼å‘Šè­¦
- èµ„æºä½¿ç”¨ç‡å‘Šè­¦

---

## ğŸ¯ æ€»ç»“

æœ¬æŒ‡å—æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„ Apache Flink å®æ—¶æµå¤„ç†æ¶æ„ï¼ŒåŒ…å«ï¼š

âœ… **å®Œæ•´çš„æŠ€æœ¯æ ˆ**ï¼šFlink + Kafka + PostgreSQL + Docker
âœ… **å®é™…ä¸šåŠ¡åœºæ™¯**ï¼šç”µå•†è®¢å•å®æ—¶å¤„ç†
âœ… **åˆ†å±‚æ•°æ®æ¶æ„**ï¼šODS â†’ DWD â†’ ç»´åº¦å…³è” â†’ ç›®æ ‡å­˜å‚¨
âœ… **é—®é¢˜è§£å†³æ–¹æ¡ˆ**ï¼šèµ„æºç®¡ç†ã€é”™è¯¯å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–
âœ… **ç›‘æ§å’Œè¿ç»´**ï¼šæŒ‡æ ‡ç›‘æ§ã€å‘Šè­¦è®¾ç½®

é€šè¿‡å®Œæ•´æ‰§è¡Œæœ¬æŒ‡å—ï¼Œæ‚¨å°†æŒæ¡ï¼š
- å®æ—¶æ•°æ®å¤„ç†æ¶æ„è®¾è®¡
- Flink é›†ç¾¤ç®¡ç†å’Œä¼˜åŒ–
- æµå¤„ç†ä½œä¸šå¼€å‘å’Œè°ƒè¯•
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œè¿ç»´

è¿™ä¸ªæ¶æ„å¯ä»¥ä½œä¸ºç”Ÿäº§ç¯å¢ƒçš„åŸºç¡€æ¨¡æ¿ï¼Œæ ¹æ®å®é™…ä¸šåŠ¡éœ€æ±‚è¿›è¡Œæ‰©å±•å’Œä¼˜åŒ–ã€‚

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
1. æŸ¥çœ‹ Flink Web UI ç›‘æ§é¢æ¿
2. æ£€æŸ¥ Docker å®¹å™¨æ—¥å¿—
3. å‚è€ƒæœ¬æ–‡æ¡£çš„é—®é¢˜è§£å†³æ–¹æ¡ˆ
4. æŸ¥é˜… Apache Flink å®˜æ–¹æ–‡æ¡£

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€ 