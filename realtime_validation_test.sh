#!/bin/bash

# ========================================
# Apache Flink å®æ—¶ä¸šåŠ¡éªŒè¯æµ‹è¯•è„šæœ¬
# ========================================

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_header() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}"
}

print_step() {
    echo -e "${PURPLE}[STEP]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    print_step "æ£€æŸ¥ç¯å¢ƒçŠ¶æ€..."
    
    # æ£€æŸ¥Docker ComposeæœåŠ¡
    if ! docker-compose ps | grep -q "Up"; then
        print_error "Docker ComposeæœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆæ‰§è¡Œ: docker-compose up -d"
        exit 1
    fi
    
    # æ£€æŸ¥Flink JobManager
    if ! curl -s http://localhost:8081/overview > /dev/null; then
        print_error "Flink JobManageræœªå°±ç»ªï¼Œè¯·ç­‰å¾…æœåŠ¡å¯åŠ¨"
        exit 1
    fi
    
    print_success "ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# éªŒè¯åˆå§‹æ•°æ®
verify_initial_data() {
    print_step "éªŒè¯åˆå§‹æ•°æ®çŠ¶æ€..."
    
    echo -e "\n${BLUE}=== æºæ•°æ®åº“åˆå§‹è®¢å• ===${NC}"
    docker exec postgres-source psql -U postgres -d source_db -c "
    SELECT order_id, user_id, product_name, order_status, order_time 
    FROM business.orders 
    ORDER BY order_id;
    " 2>/dev/null | grep -E "(order_id|---|[0-9]+)"
    
    echo -e "\n${BLUE}=== æ£€æŸ¥Flinkä½œä¸šçŠ¶æ€ ===${NC}"
    local job_count=$(docker exec jobmanager flink list 2>/dev/null | grep -c "RUNNING" || echo "0")
    print_info "è¿è¡Œä¸­çš„Flinkä½œä¸šæ•°é‡: $job_count"
    
    if [ "$job_count" -lt 4 ]; then
        print_warning "Flinkä½œä¸šæ•°é‡ä¸è¶³ï¼Œè¯·ç¡®ä¿å·²æ‰§è¡Œæ‰€æœ‰SQLè„šæœ¬"
        print_info "æ‰§è¡Œå‘½ä»¤ï¼š"
        echo "  docker exec sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/1_cdc_source_to_kafka.sql"
        echo "  docker exec sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/2_dwd_layer.sql"
        echo "  docker exec sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/3_dimension_join.sql"
        echo "  docker exec sql-client /opt/flink/bin/sql-client.sh -f /opt/sql/4_sink_to_postgres.sql"
        read -p "æ˜¯å¦ç»§ç»­æµ‹è¯•ï¼Ÿ (y/n): " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
}

# æ‰§è¡Œå®æ—¶ä¸šåŠ¡æ“ä½œ
execute_realtime_operations() {
    print_step "æ‰§è¡Œå®æ—¶ä¸šåŠ¡æ“ä½œ..."
    
    # ç”Ÿæˆå”¯ä¸€çš„è®¢å•ID
    ORDER_ID=$((2000 + RANDOM % 1000))
    START_TIME=$(date '+%Y-%m-%d %H:%M:%S')
    
    print_info "æµ‹è¯•è®¢å•ID: $ORDER_ID"
    print_info "å¼€å§‹æ—¶é—´: $START_TIME"
    
    # 1. æ’å…¥æ–°è®¢å•
    print_info "1. æ’å…¥æ–°è®¢å• (PENDINGçŠ¶æ€)"
    docker exec postgres-source psql -U postgres -d source_db -c "
    INSERT INTO business.orders (order_id, user_id, product_name, product_category, quantity, unit_price, total_amount, order_status, order_time, updated_at)
    VALUES ($ORDER_ID, 1001, 'AirPods Pro æµ‹è¯•', 'ç”µå­äº§å“', 1, 1999.00, 1999.00, 'PENDING', NOW(), NOW());
    " >/dev/null 2>&1
    
    if [ $? -eq 0 ]; then
        print_success "è®¢å•æ’å…¥æˆåŠŸ"
    else
        print_error "è®¢å•æ’å…¥å¤±è´¥"
        return 1
    fi
    
    sleep 3
    
    # 2. æ›´æ–°è®¢å•çŠ¶æ€ä¸ºSHIPPED
    print_info "2. æ›´æ–°è®¢å•çŠ¶æ€ (PENDING â†’ SHIPPED)"
    docker exec postgres-source psql -U postgres -d source_db -c "
    UPDATE business.orders 
    SET order_status = 'SHIPPED', updated_at = NOW() 
    WHERE order_id = $ORDER_ID;
    " >/dev/null 2>&1
    
    if [ $? -eq 0 ]; then
        print_success "è®¢å•çŠ¶æ€æ›´æ–°ä¸ºSHIPPED"
    else
        print_error "è®¢å•çŠ¶æ€æ›´æ–°å¤±è´¥"
        return 1
    fi
    
    sleep 3
    
    # 3. å®Œæˆè®¢å•
    print_info "3. å®Œæˆè®¢å• (SHIPPED â†’ COMPLETED)"
    docker exec postgres-source psql -U postgres -d source_db -c "
    UPDATE business.orders 
    SET order_status = 'COMPLETED', updated_at = NOW() 
    WHERE order_id = $ORDER_ID;
    " >/dev/null 2>&1
    
    if [ $? -eq 0 ]; then
        print_success "è®¢å•å®Œæˆ"
    else
        print_error "è®¢å•å®Œæˆå¤±è´¥"
        return 1
    fi
    
    # å­˜å‚¨è®¢å•IDä¾›åç»­éªŒè¯ä½¿ç”¨
    echo $ORDER_ID > /tmp/test_order_id.txt
}

# éªŒè¯æ•°æ®æµè½¬
verify_data_flow() {
    print_step "éªŒè¯æ•°æ®æµè½¬..."
    
    ORDER_ID=$(cat /tmp/test_order_id.txt 2>/dev/null || echo "2006")
    
    # éªŒè¯CDCå±‚
    print_info "éªŒè¯ODSå±‚CDCæ•°æ®æ•è·..."
    local ods_count=$(timeout 10s docker exec kafka kafka-console-consumer \
        --bootstrap-server localhost:9092 \
        --topic ods_orders \
        --from-beginning \
        --timeout-ms 8000 2>/dev/null | grep -c "$ORDER_ID" 2>/dev/null || echo "0")
    ods_count=$(echo "$ods_count" | tr -d '\n\r' | grep -o '[0-9]*' | head -1)
    [ -z "$ods_count" ] && ods_count=0
    
    if [ "$ods_count" -gt 0 ]; then
        print_success "ODSå±‚æ•°æ®éªŒè¯é€šè¿‡ (å‘ç° $ods_count æ¡è®°å½•)"
    else
        print_warning "ODSå±‚æœªå‘ç°æµ‹è¯•æ•°æ®ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´"
    fi
    
    # éªŒè¯DWDå±‚
    print_info "éªŒè¯DWDå±‚æ•°æ®æ¸…æ´—..."
    local dwd_count=$(timeout 10s docker exec kafka kafka-console-consumer \
        --bootstrap-server localhost:9092 \
        --topic dwd_orders \
        --from-beginning \
        --timeout-ms 8000 2>/dev/null | grep -c "$ORDER_ID" 2>/dev/null || echo "0")
    dwd_count=$(echo "$dwd_count" | tr -d '\n\r' | grep -o '[0-9]*' | head -1)
    [ -z "$dwd_count" ] && dwd_count=0
    
    if [ "$dwd_count" -gt 0 ]; then
        print_success "DWDå±‚æ•°æ®éªŒè¯é€šè¿‡ (å‘ç° $dwd_count æ¡è®°å½•)"
    else
        print_warning "DWDå±‚æœªå‘ç°æµ‹è¯•æ•°æ®"
    fi
    
    # éªŒè¯ç»´åº¦å…³è”
    print_info "éªŒè¯ç»´åº¦å…³è”ç»“æœ..."
    local result_count=$(timeout 10s docker exec kafka kafka-console-consumer \
        --bootstrap-server localhost:9092 \
        --topic result_orders_with_user_info \
        --from-beginning \
        --timeout-ms 8000 2>/dev/null | grep -c "$ORDER_ID" 2>/dev/null || echo "0")
    result_count=$(echo "$result_count" | tr -d '\n\r' | grep -o '[0-9]*' | head -1)
    [ -z "$result_count" ] && result_count=0
    
    if [ "$result_count" -gt 0 ]; then
        print_success "ç»´åº¦å…³è”éªŒè¯é€šè¿‡ (å‘ç° $result_count æ¡è®°å½•)"
    else
        print_warning "ç»´åº¦å…³è”å±‚æœªå‘ç°æµ‹è¯•æ•°æ®"
    fi
}

# éªŒè¯æœ€ç»ˆç»“æœå’Œå»¶è¿Ÿ
verify_final_results() {
    print_step "éªŒè¯æœ€ç»ˆç»“æœå’Œå»¶è¿Ÿ..."
    
    ORDER_ID=$(cat /tmp/test_order_id.txt 2>/dev/null || echo "2006")
    
    # ç­‰å¾…æ•°æ®å†™å…¥
    print_info "ç­‰å¾…æ•°æ®å†™å…¥æœ€ç»ˆæ•°æ®åº“..."
    sleep 10
    
    # æ£€æŸ¥æœ€ç»ˆç»“æœ
    echo -e "\n${BLUE}=== æœ€ç»ˆç»“æœéªŒè¯ ===${NC}"
    local final_result=$(docker exec postgres-sink psql -U postgres -d sink_db -c "
    SELECT 
        order_id,
        username,
        city,
        product_name,
        total_amount,
        order_status,
        TO_CHAR(processed_time, 'YYYY-MM-DD HH24:MI:SS') as processed_time
    FROM result.orders_with_user_info 
    WHERE order_id = $ORDER_ID
    ORDER BY processed_time DESC
    LIMIT 3;
    " 2>/dev/null)
    
    if echo "$final_result" | grep -q "$ORDER_ID"; then
        print_success "æœ€ç»ˆç»“æœéªŒè¯é€šè¿‡"
        echo "$final_result" | grep -E "(order_id|---|$ORDER_ID)"
        
        # å»¶è¿Ÿåˆ†æ
        echo -e "\n${BLUE}=== ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†æ ===${NC}"
        docker exec postgres-sink psql -U postgres -d sink_db -c "
        SELECT 
            order_id,
            order_status,
            ROUND(CAST(DATE_PART('epoch', processed_time - order_time) AS NUMERIC), 2) as latency_seconds,
            TO_CHAR(order_time, 'HH24:MI:SS') as source_time,
            TO_CHAR(processed_time, 'HH24:MI:SS') as result_time
        FROM result.orders_with_user_info 
        WHERE order_id = $ORDER_ID
        ORDER BY processed_time DESC;
        " 2>/dev/null
        
    else
        print_error "æœ€ç»ˆç»“æœéªŒè¯å¤±è´¥ï¼Œæœªåœ¨ç›®æ ‡æ•°æ®åº“ä¸­æ‰¾åˆ°æµ‹è¯•æ•°æ®"
        
        # å°è¯•æ•…éšœæ’é™¤
        print_info "æ‰§è¡Œæ•…éšœæ’é™¤..."
        
        # æ£€æŸ¥Flinkä½œä¸šçŠ¶æ€
        print_info "Flinkä½œä¸šçŠ¶æ€:"
        docker exec jobmanager flink list 2>/dev/null | grep -E "(Job ID|RUNNING|FAILED)"
        
        # æ£€æŸ¥Sinkä½œä¸šæ˜¯å¦è¿è¡Œ
        local sink_jobs=$(curl -s http://localhost:8081/jobs/overview 2>/dev/null | grep -o '"state":"RUNNING"' | wc -l || echo "0")
        print_info "è¿è¡Œä¸­çš„ä½œä¸šæ•°é‡: $sink_jobs"
        
        return 1
    fi
}

# æ€§èƒ½ç»Ÿè®¡
performance_summary() {
    print_step "ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š..."
    
    echo -e "\n${BLUE}=== æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š ===${NC}"
    
    # æ€»è®¢å•æ•°é‡
    local total_orders=$(docker exec postgres-sink psql -U postgres -d sink_db -c "
    SELECT COUNT(*) FROM result.orders_with_user_info;
    " 2>/dev/null | grep -E "^[[:space:]]*[0-9]+[[:space:]]*$" | tr -d ' ')
    
    # å¹³å‡å»¶è¿Ÿ
    local avg_latency=$(docker exec postgres-sink psql -U postgres -d sink_db -c "
    SELECT ROUND(CAST(AVG(DATE_PART('epoch', processed_time - order_time)) AS NUMERIC), 2) 
    FROM result.orders_with_user_info 
    WHERE processed_time > order_time;
    " 2>/dev/null | grep -E "^[[:space:]]*[0-9]+\.[0-9]+[[:space:]]*$" | tr -d ' ')
    
    # Flinké›†ç¾¤èµ„æº
    local cluster_info=$(curl -s http://localhost:8081/overview 2>/dev/null)
    local taskmanagers=$(echo "$cluster_info" | grep -o '"taskmanagers":[0-9]*' | grep -o '[0-9]*')
    local slots_total=$(echo "$cluster_info" | grep -o '"slots-total":[0-9]*' | grep -o '[0-9]*')
    local slots_available=$(echo "$cluster_info" | grep -o '"slots-available":[0-9]*' | grep -o '[0-9]*')
    
    echo "ğŸ“Š æ•°æ®å¤„ç†ç»Ÿè®¡:"
    echo "  â€¢ æ€»å¤„ç†è®¢å•æ•°: ${total_orders:-0}"
    echo "  â€¢ å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿ: ${avg_latency:-N/A} ç§’"
    echo ""
    echo "ğŸ”§ é›†ç¾¤èµ„æºçŠ¶æ€:"
    echo "  â€¢ TaskManageræ•°é‡: ${taskmanagers:-0}"
    echo "  â€¢ æ€»Task Slots: ${slots_total:-0}"
    echo "  â€¢ å¯ç”¨Task Slots: ${slots_available:-0}"
    echo "  â€¢ èµ„æºåˆ©ç”¨ç‡: $((100 - slots_available * 100 / slots_total))%"
    echo ""
    
    # å»¶è¿Ÿè¯„ä¼°
    if [ ! -z "$avg_latency" ] && [ "$(echo "$avg_latency < 5" | bc -l 2>/dev/null || echo "1")" = "1" ]; then
        print_success "âœ… å»¶è¿Ÿæ€§èƒ½: ä¼˜ç§€ (< 5ç§’)"
    elif [ ! -z "$avg_latency" ] && [ "$(echo "$avg_latency < 10" | bc -l 2>/dev/null || echo "1")" = "1" ]; then
        print_warning "âš ï¸ å»¶è¿Ÿæ€§èƒ½: è‰¯å¥½ (< 10ç§’)"
    else
        print_warning "âš ï¸ å»¶è¿Ÿæ€§èƒ½: éœ€è¦ä¼˜åŒ– (â‰¥ 10ç§’)"
    fi
}

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
cleanup() {
    rm -f /tmp/test_order_id.txt
}

# ä¸»å‡½æ•°
main() {
    print_header "Apache Flink å®æ—¶ä¸šåŠ¡éªŒè¯æµ‹è¯•"
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_environment
    
    # éªŒè¯åˆå§‹æ•°æ®
    verify_initial_data
    
    # æ‰§è¡Œå®æ—¶ä¸šåŠ¡æ“ä½œ
    if execute_realtime_operations; then
        print_success "å®æ—¶ä¸šåŠ¡æ“ä½œå®Œæˆ"
        
        # éªŒè¯æ•°æ®æµè½¬
        verify_data_flow
        
        # éªŒè¯æœ€ç»ˆç»“æœ
        if verify_final_results; then
            print_success "ğŸ‰ å®æ—¶éªŒè¯æµ‹è¯•é€šè¿‡ï¼"
        else
            print_error "âŒ å®æ—¶éªŒè¯æµ‹è¯•å¤±è´¥"
        fi
        
        # æ€§èƒ½ç»Ÿè®¡
        performance_summary
        
    else
        print_error "å®æ—¶ä¸šåŠ¡æ“ä½œå¤±è´¥"
        exit 1
    fi
    
    # æ¸…ç†
    cleanup
    
    print_header "æµ‹è¯•å®Œæˆ"
    echo -e "è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ä¸Šæ–¹è¾“å‡ºç»“æœ"
    echo -e "å¦‚éœ€é‡å¤æµ‹è¯•ï¼Œè¯·å†æ¬¡è¿è¡Œæ­¤è„šæœ¬"
}

# è¿è¡Œä¸»å‡½æ•°
main "$@" 