services:
  # PostgreSQL 源数据库
  postgres-source:
    image: postgres:15
    hostname: postgres-source
    container_name: postgres-source
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: source_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./postgres_source/init:/docker-entrypoint-initdb.d
      - postgres_source_data:/var/lib/postgresql/data
    command: |
      postgres -c wal_level=logical 
               -c max_replication_slots=10 
               -c max_wal_senders=10
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d source_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PostgreSQL 目标数据库
  postgres-sink:
    image: postgres:15
    hostname: postgres-sink
    container_name: postgres-sink
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: sink_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - ./postgres_sink/init:/docker-entrypoint-initdb.d
      - postgres_sink_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d sink_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka 集群
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 10s
      retries: 5

  # Flink JobManager
  jobmanager:
    image: flink:1.18-scala_2.12
    hostname: jobmanager
    container_name: jobmanager
    ports:
      - "8081:8081"
    command: |
      bash -c "
        cp /opt/flink/lib-extra/*.jar /opt/flink/lib/
        /docker-entrypoint.sh jobmanager
      "
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        state.backend: hashmap
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        state.savepoints.dir: file:///tmp/flink-savepoints
        execution.checkpointing.interval: 30s
        execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION
        parallelism.default: 1
    volumes:
      - /tmp/flink-checkpoints-directory:/tmp/flink-checkpoints
      - /tmp/flink-savepoints-directory:/tmp/flink-savepoints
      - ./flink/jars:/opt/flink/lib-extra
    depends_on:
      postgres-source:
        condition: service_healthy
      postgres-sink:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/overview"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Flink TaskManager
  taskmanager:
    image: flink:1.18-scala_2.12
    depends_on:
      jobmanager:
        condition: service_healthy
    command: |
      bash -c "
        cp /opt/flink/lib-extra/*.jar /opt/flink/lib/
        /docker-entrypoint.sh taskmanager
      "
    scale: 2
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 4
        state.backend: hashmap
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        state.savepoints.dir: file:///tmp/flink-savepoints
        parallelism.default: 1
    volumes:
      - /tmp/flink-checkpoints-directory:/tmp/flink-checkpoints
      - /tmp/flink-savepoints-directory:/tmp/flink-savepoints
      - ./flink/jars:/opt/flink/lib-extra

  # Flink SQL 客户端
  sql-client:
    image: flink:1.18-scala_2.12
    hostname: sql-client
    container_name: sql-client
    depends_on:
      jobmanager:
        condition: service_healthy
      kafka:
        condition: service_healthy
      postgres-source:
        condition: service_healthy
      postgres-sink:
        condition: service_healthy
    command: 
      - bash
      - -c
      - |
        echo 'Copying JAR files to lib directory...'
        cp /opt/flink/lib-extra/*.jar /opt/flink/lib/
        
        echo 'Waiting for all services to be ready...'
        sleep 30
        
        echo 'Creating Kafka topics for data pipeline...'
        kafka-topics --bootstrap-server kafka:29092 --create --topic ods_orders --partitions 4 --replication-factor 1 || true
        kafka-topics --bootstrap-server kafka:29092 --create --topic ods_users --partitions 4 --replication-factor 1 || true
        kafka-topics --bootstrap-server kafka:29092 --create --topic dwd_orders --partitions 4 --replication-factor 1 || true
        kafka-topics --bootstrap-server kafka:29092 --create --topic dwd_users --partitions 4 --replication-factor 1 || true
        kafka-topics --bootstrap-server kafka:29092 --create --topic result_orders_with_user_info --partitions 4 --replication-factor 1 || true
        
        echo 'All topics created successfully!'
        echo '========================================='
        echo 'Apache Flink + Kafka 流处理架构 Ready!'
        echo '========================================='
        echo 'SQL Client is ready. You can now connect and execute SQL files.'
        echo 'Available SQL files:'
        echo '  1. /opt/sql/1_cdc_source_to_kafka.sql'
        echo '  2. /opt/sql/2_dwd_layer.sql'  
        echo '  3. /opt/sql/3_dimension_join.sql'
        echo '  4. /opt/sql/4_sink_to_postgres.sql'
        echo ''
        echo 'To connect: docker exec -it sql-client /opt/flink/bin/sql-client.sh'
        echo 'To run validation: ./realtime_validation_test.sh'
        echo '========================================='
        
        tail -f /dev/null
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
    volumes:
      - ./flink/jars:/opt/flink/lib-extra
      - ./flink/sql:/opt/sql

networks:
  default:
    name: flink-kafka-network

volumes:
  postgres_source_data:
  postgres_sink_data: 